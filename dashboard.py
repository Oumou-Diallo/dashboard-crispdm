import streamlit as st
import pandas as pd
import os
import plotly.express as px
from joblib import load
import numpy as np
from tensorflow.keras.models import load_model  # Pour charger l'autoencodeur

# --- Configuration g√©n√©rale ---
st.set_page_config(page_title="Dashboard CRISP-DM", layout="wide")
st.markdown("""
    <style>
    .main {
        background-color: #f5f7fa;
    }
    .stButton>button {
        background-color: #4CAF50;
        color: white;
        border-radius: 8px;
        padding: 0.5em 1em;
    }
    </style>
""", unsafe_allow_html=True)

st.title("üåê Analyse de la Consommation d'√ânergie dans le RAN 5G")
st.markdown("""
Bienvenue sur ce dashboard interactif permettant d'explorer la consommation
d'√©nergie en fonction des clusters issus du Deep Clustering appliqu√© √† un DU simul√©.
""")

# --- Chargement des donn√©es et des mod√®les ---
st.sidebar.header("Configuration")

data_file = "data/processed_data.csv"
cluster_model_path = "models/kmeans.joblib"
scaler_path = "models/scaler.joblib"
autoencoder_path = "models/autoencoder.h5"  # Chemin vers le mod√®le Autoencoder
features_path = "models/features.joblib"  # Liste des features utilis√©es pour l'entra√Ænement

if not os.path.exists(data_file):
    st.sidebar.error("Fichier de donn√©es non trouv√©.")
    st.stop()

full_data = pd.read_csv(data_file)

try:
    # Charger tous les mod√®les n√©cessaires
    kmeans_model = load(cluster_model_path)
    scaler = load(scaler_path)
    autoencoder = load_model(autoencoder_path)
    feature_columns = load(features_path)  # Liste des colonnes utilis√©es pour le clustering
    st.sidebar.success("Mod√®les charg√©s avec succ√®s ‚úÖ")
except Exception as e:
    st.sidebar.error(f"Erreur lors du chargement des mod√®les : {e}")
    st.stop()

# --- V√©rification des colonnes ---
required_cols = ['energy_per_packet', 'Split_Type'] + feature_columns
missing = [c for c in required_cols if c not in full_data.columns]
if missing:
    st.error(f"‚ùå Colonnes manquantes dans 'processed_data.csv' : {', '.join(missing)}")
    st.stop()

# --- Calcul des clusters en temps r√©el ---
@st.cache_data
def calculate_clusters(data, _autoencoder, _kmeans, _scaler, features):
    """Calcule les clusters √† partir des donn√©es brutes"""
    # S√©lection et normalisation des features
    X = data[features]
    X_scaled = _scaler.transform(X)
    
    # Repr√©sentation latente via Autoencoder
    latent_rep = _autoencoder.predict(X_scaled, verbose=0)
    
    # Pr√©diction des clusters avec KMeans
    clusters = _kmeans.predict(latent_rep)
    return clusters

# Ajout des clusters aux donn√©es
full_data['cluster_deep'] = calculate_clusters(
    full_data, 
    autoencoder, 
    kmeans_model, 
    scaler, 
    feature_columns
)

# --- Aper√ßu des donn√©es ---
st.subheader("üî¢ Aper√ßu des donn√©es")
st.dataframe(full_data.head(10))

# --- R√©partition des clusters ---
st.subheader("üìä R√©partition des clusters Deep Clustering")
cluster_counts = full_data['cluster_deep'].value_counts().sort_index()
cluster_df = cluster_counts.reset_index()
cluster_df.columns = ['cluster_deep', 'count']

fig1 = px.bar(
    cluster_df,
    x='cluster_deep', y='count',
    labels={'cluster_deep': 'Cluster', 'count': 'Nombre de points'},
    title="Nombre d‚Äô√©chantillons par cluster",
    color='cluster_deep'
)
st.plotly_chart(fig1, use_container_width=True)

# --- √ânergie moyenne par cluster ---
st.subheader("‚ö° √ânergie moyenne par cluster Deep Clustering")
energy_mean = full_data.groupby('cluster_deep')['energy_per_packet'].mean().sort_values()
fig2 = px.bar(
    energy_mean.reset_index(),
    x='cluster_deep', y='energy_per_packet',
    labels={'cluster_deep': 'Cluster', 'energy_per_packet': '√ânergie moyenne (J/paquet)'},
    title="Consommation moyenne par cluster",
    color='energy_per_packet',
    color_continuous_scale=px.colors.sequential.Viridis
)
st.plotly_chart(fig2, use_container_width=True)

# --- Distribution des splits par cluster ---
st.subheader("üìå Distribution des splits dans chaque cluster")
split_dist = full_data.groupby('cluster_deep')['Split_Type'].value_counts(normalize=True).unstack(fill_value=0)
fig3 = px.bar(
    split_dist,
    barmode='stack',
    labels={'value': 'Proportion', 'cluster_deep': 'Cluster', 'Split_Type': 'Type de Split'},
    title="Proportion des types de splits par cluster",
    color_discrete_sequence=px.colors.qualitative.Pastel
)
st.plotly_chart(fig3, use_container_width=True)

# --- Analyse interactive des splits ---
st.subheader("üîç Analyse personnalis√©e des splits")
choice = st.radio("Souhaitez-vous identifier :", ["Le split le PLUS √©nergivore", "Le split le MOINS √©nergivore"])

split_energy = full_data.groupby('Split_Type')['energy_per_packet'].mean()

if choice == "Le split le PLUS √©nergivore":
    target_split = split_energy.idxmax()
    value = split_energy.max()
    st.success(f"üî∫ Le split **{int(target_split)}** est le PLUS √©nergivore avec une moyenne de **{value:.2e} J/paquet**.")
else:
    target_split = split_energy.idxmin()
    value = split_energy.min()
    st.success(f"üîª Le split **{int(target_split)}** est le MOINS √©nergivore avec une moyenne de **{value:.2e} J/paquet**.")

# --- Option bouton de rechargement / reset ---
if st.button("üîÑ Rafra√Æchir les donn√©es"):
    st.experimental_rerun()
